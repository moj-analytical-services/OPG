{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9dce19a-0b8e-4890-a9d2-d22dc9a1aba4",
   "metadata": {},
   "source": [
    "# OPG : LPA Data Pre-processing and Cleaning tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517bdf9-08ba-4cc1-8c2f-b01ffdf7971d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before you can run this project, you need to install some Python packages using the terminal:\n",
    "\n",
    "\n",
    "### create and activate  a virtual environment\n",
    "cd OPG\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "\n",
    "### install the python packages required\n",
    "pip install -r requirements.txt\n",
    "\n",
    "#pip install --upgrade pip\n",
    "\n",
    "### Updating your branch with main\n",
    "When working on your models it is likely that your branch will get out of date with the main branch. To update you branch with the latest changes from main open a terminal and run the following:\n",
    "\n",
    "Check your working tree, commit/push any changes if required\n",
    "\n",
    "git status\n",
    "Switch to the main branch and collect the latest changes, if any\n",
    "\n",
    "git switch main\n",
    "git fetch\n",
    "git pull\n",
    "Switch back to your branch and merge in the changes from main\n",
    "\n",
    "git switch <your initial>/model-a-development\n",
    "git merge main -m \"update branch with main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765f151-ee2c-44b2-8fcd-0a438f11633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-comment and Run the below code if there is an error with packages:\n",
    "\n",
    "!pip install arrow_pd_parser\n",
    "!pip install pydbtools\n",
    "!pip install arrow_pd_parser\n",
    "!pip install pydbtools\n",
    "!pip install xlsxwriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bed50b-9b72-4d69-9326-fd1f690522fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "os.getcwd()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import awswrangler as wr\n",
    "#import statsmodels.api as sm\n",
    "#import tensorflow as tf\n",
    "import boto3\n",
    "import getpass\n",
    "import pytz\n",
    "#import openpyxl\n",
    "#import matplotlib\n",
    "import csv\n",
    "from arrow_pd_parser import reader, writer\n",
    "\n",
    "import pydbtools as pydb\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "from matplotlib import rc\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# consistent plot size wherever not specifiied\n",
    "from pylab import rcParams\n",
    "mpl.rcParams['figure.figsize'] = (15,8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "rcParams['xtick.labelsize'] = 14\n",
    "rcParams['ytick.labelsize'] = 14\n",
    "rcParams['axes.labelsize'] = 14\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import xlsxwriter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# consistent plot size wherever not specifiied\n",
    "from pylab import rcParams\n",
    "mpl.rcParams['figure.figsize'] = (15,8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "rcParams['xtick.labelsize'] = 14\n",
    "rcParams['ytick.labelsize'] = 14\n",
    "rcParams['axes.labelsize'] = 14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd602cf8-4885-43a5-82a9-429f8ce730b0",
   "metadata": {},
   "source": [
    "# LPA Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4208661-eff3-4123-920a-99ed7ce72fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the List of CSV Files\n",
    "csv_files = [f for f in os.listdir(\"csv_files\") if f.endswith('.csv')]\n",
    "print(csv_files)\n",
    "\n",
    "# Loading the CSV Files into a DataFrame\n",
    "dfs = []\n",
    "\n",
    "for csv in csv_files:\n",
    "    df = pd.read_csv(os.path.join(\"csv_files\", csv), \\\n",
    "                     usecols = [\"receiptdate\",\"cases_glueexporteddate\",\"uid\",\"type\",\"casesubtype\",\"status\",\"donor_dob\",\"donor_postcode\",\"donor_gender\"], \\\n",
    "                     encoding = 'utf-8', \\\n",
    "                     error_bad_lines = False, \\\n",
    "                     engine = \"python\")\n",
    "    dfs.append(df)\n",
    "    \n",
    "# Concatenating the DataFrames\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#pd.concat([x.ix[:, cols_to_keep] for x in pd.read_csv(..., chunksize=200)]) \n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19756c99-6632-4f3f-b123-5f9394198786",
   "metadata": {},
   "source": [
    "# S3 Bucket Data Extraction for LPA Data (actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991a0c6-dc43-4c09-83e6-773c016d3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify the type of data set and pre-processing: \n",
    "## Import, manipulate, and clean the data and impute missing values\n",
    "\n",
    "## Import the dataset and read in the actual data\n",
    "#df = wr.s3.read_csv([path1_s3], sep = ',', parse_dates=True) #import divorce data\n",
    "#read data\n",
    "#def parser(s):\n",
    "#    return datetime.strptime(s, '%Y-%m-%d')\n",
    "#df = wr.s3.read_csv([path1_s3], parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "## iterating the columns\n",
    "#for col in df.columns:\n",
    "#    print(col)\n",
    "\n",
    "\n",
    "#lpa=LPA_data[[\"receiptdate\",\"cases_glueexporteddate\",\"uid\",\"type\",\"casesubtype\",\"status\",\"donor_dob\",\"donor_postcode\",\"donor_gender\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268ef2b-4e72-4080-a918-e7bfddc40822",
   "metadata": {},
   "source": [
    "# Set the date you want to extract data based on the latest date extrated LPA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93434d88-6814-4c5b-8d96-e33a7eaa70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first date to be considered:\n",
    "snapshot_start = '2006-12-31'\n",
    "\n",
    "snapshot_end = final_df.values[7].astype(str)[7]\n",
    "#snapshot_end = final_df.astype(str)\n",
    "#snapshot_start = datetime.strptime(snapshot_end, '%Y-%m-%d') - relativedelta(months= 1)\n",
    "#snapshot_start = snapshot_start.strftime('%Y-%m-%d')\n",
    "snapshot_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c09c2-54bc-42df-b55b-ea188f2babb5",
   "metadata": {},
   "source": [
    "# Data pre-processing and cleaning - data engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc0e1c-b824-4822-a8e5-20041f465a65",
   "metadata": {},
   "source": [
    "## Meta data and Variable selection and Data Cleaning for the LPA data in Data Warehouse:\n",
    "\n",
    "Goal: to work out how many people applied for lpa and recieved the power of atthorney and how many applications in a year/month/week by age group since 2007? \n",
    "\n",
    "### ages over 19 years old\n",
    "\n",
    "#### Unique case reference for each donor = [donor_dob + donor_postcode + donor_gender]\n",
    "\n",
    "##### Sort by the unique id and count how many application\n",
    "\n",
    "###### and then dermine Whether the application type [casesubtype] is hw=health and welfare or pfa=property and finance\n",
    "\n",
    "###### how many certificate provider (cp) for each lpa application?\n",
    "\n",
    "###### Location based data and geographical data for the donor can be used to identify the financial situation and wherether they are located in England or Wales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50385b9d-958f-4a48-958b-bee05777d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the records:\n",
    "df_filtered = final_df\n",
    "\n",
    "## Convert the receipt date to date format \n",
    "df_filtered['receiptdate'] = pd.to_datetime(df_filtered['receiptdate'], errors = 'coerce').dt.date\n",
    "\n",
    "## Filter records between the selected dates\n",
    "df_filtered = df_filtered.loc[(df_filtered['receiptdate'] > pd.to_datetime(snapshot_start))]\n",
    "df_filtered = df_filtered.loc[(df_filtered['receiptdate'] < pd.to_datetime(snapshot_end))]\n",
    "\n",
    "## Filter the dataframe to select only lpa type records\n",
    "df_filtered = df_filtered.loc[(df_filtered['type'] == 'lpa')]\n",
    "\n",
    "# Create a dataframe of the selected columns\n",
    "## Select the appropriate variable to be forecasted\n",
    "df = df_filtered[[\"receiptdate\",\"uid\",\"casesubtype\",\"status\",\"donor_dob\",\"donor_postcode\",\"donor_gender\"]]\n",
    "\n",
    "## Remove Null values and records\n",
    "lpa_df = df.dropna()\n",
    "\n",
    "# Extract age by subtracting 'receiptdate' and 'donor_dob'\n",
    "lpa_df['age'] = pd.to_datetime(lpa_df['receiptdate'], errors = 'coerce').dt.year - pd.to_datetime(lpa_df['donor_dob'], errors = 'coerce').dt.year\n",
    "#lpa_df['age'] = relativedelta(date, dob).years\n",
    "\n",
    "# Convert the donor_dob column to a datatime format\n",
    "lpa_df['donor_dob'] = pd.to_datetime(lpa_df['donor_dob'], errors = 'coerce').dt.date\n",
    "\n",
    "# Convert the ‘receiptdate’ column to datetime format for proper plotting.\n",
    "# Convert 'receiptdate' to datetime format \n",
    "lpa_df['receiptdate'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce')\n",
    "\n",
    "# Extract year from 'receiptdate'\n",
    "lpa_df['year'] = lpa_df['receiptdate'].dt.year\n",
    "\n",
    "## Set index\n",
    "#df['receiptdate'] = pd.to_datetime(df['receiptdate'])\n",
    "\n",
    "#df = df.set_index('receiptdate').asfreq('D')\n",
    "\n",
    "####df['receiptdate'] = df.set_index('receiptdate',inplace=True)\n",
    "\n",
    "#df.index = df.index.to_period('D')\n",
    "                            \n",
    "###print(df.head())\n",
    "###print(df.tail())\n",
    "\n",
    "\n",
    "#lpa_df['age'] = pd.to_datetime(df['receiptdate'], errors = 'coerce').dt.date - pd.to_datetime(df['donor_dob'], errors = 'coerce').dt.date\n",
    "#lpa_df['receiptdate'] = pd.to_datetime(lpa_df['receiptdate']).dt.date#.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "#print(lpa_df)#['receiptdate']\n",
    "#lpa_df\n",
    "\n",
    "#print(lpa_df['age'])\n",
    "\n",
    "## infer the frequency of the data:\n",
    "###lpa_df = df\n",
    "\n",
    "#lpa_df = df.asfreq(pd.infer_freq(df.index))\n",
    "\n",
    "#lpa_df = lpa_df[start_date:end_date]\n",
    "\n",
    "#start_date_years = datetime.strptime(start_date, \n",
    "#                                     '%Y-%m-%d') + relativedelta(years = 0)\n",
    "#print(start_date_years)\n",
    "\n",
    "#start_date_formatted = start_date_years.date()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e48bf-b1c7-4d9c-8521-e4c8619c8327",
   "metadata": {},
   "source": [
    "# Visualisation of the time series\n",
    "## Virtualisation of the LPA Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87f746-f458-4ab7-ab2e-8ce7243fbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 'age' against 'receiptdate'\n",
    "\n",
    "## --------------------------------------------------------------------------------  ##\n",
    "# Create a scatter plot with ‘receiptdate’ as the x-axis and ‘age’ as the y-axis.\n",
    "# Display the plot with appropriate labels and a grid.\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(lpa_df['receiptdate'], lpa_df['age'], alpha=0.5)\n",
    "plt.title('Age vs Receipt Date')\n",
    "plt.xlabel('Receipt Date')\n",
    "plt.ylabel('Age')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "## --------------------------------------------------------------------------------  ##\n",
    "# Create a histogram of the 'age' column\n",
    "\n",
    "# This code will produce a histogram that displays the frequency distribution of ages in your dataset. \n",
    "# The bins parameter determines the number of bins used in the histogram, and you can adjust this number\n",
    "# to change the granularity of your histogram.\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(lpa_df['age'], bins=20, alpha=0.7, color='blue')\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "## --------------------------------------------------------------------------------  ##\n",
    "# Create a line chart of age against receipt date\n",
    "# Sort the DataFrame by 'receiptdate' to ensure the line chart is ordered\n",
    "lpa_df.sort_values('receiptdate', inplace=True)\n",
    "\n",
    "# Plot 'age' against 'receiptdate' using a line chart\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(lpa_df['receiptdate'], lpa_df['age'], marker='o', linestyle='-', color='blue')\n",
    "plt.title('Age vs Receipt Date')\n",
    "plt.xlabel('Receipt Date')\n",
    "plt.ylabel('Age')\n",
    "plt.grid(True)\n",
    "\n",
    "## --------------------------------------------------------------------------------  ##\n",
    "# Produce a line chart that displays the average age of individuals for each year based on the receipt dates in your dataset.\n",
    "# The data points are connected with a line, which helps in identifying any trends or patterns over the years.\n",
    "\n",
    "# Group the data by year and calculate the average age for each year\n",
    "age_by_year = lpa_df.groupby('year')['age'].mean().reset_index()\n",
    "\n",
    "# Plot 'age' against 'year' using a line chart\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(age_by_year['year'], age_by_year['age'], marker='o', linestyle='-', color='blue')\n",
    "plt.title('Average Age vs Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Age')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817f1a4-4782-4762-bd6e-715e96728f49",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "The trend in the line chart indicates the changes in the average age of individuals over the years, \n",
    "based on the receipt dates from your dataset.\n",
    "Such a visualization can help identify patterns, \n",
    "such as whether the average age is increasing, decreasing, or remaining relatively stable over time.\n",
    "\n",
    "For example:\n",
    "An upward trend would suggest that the average age is increasing each year.\n",
    "A downward trend would indicate that the average age is decreasing.\n",
    "A flat line would imply that there is little to no change in the average age over the years.\n",
    "These trends can be influenced by various factors, such as the demographics of the population being studied, \n",
    "changes in policies, or other external factors that might affect the age distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819b606-ffd9-4e8c-bcc6-ac54e81cf4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the Actuals\n",
    "\n",
    "# lpa_series = lpa_df['age']\n",
    "# #lpa_series = df.squeeze()\n",
    "# plt.figure(figsize=(28, 14))\n",
    "# plt.plot(lpa_series)\n",
    "# plt.title('UK Actual LPA Data', fontsize=20)\n",
    "# plt.ylabel('Age', fontsize=16)\n",
    "# plt.axvline(pd.to_datetime(df['receiptdate'], errors = 'coerce').dt.year, color = 'k', linestyle='--', alpha = 0.2)\n",
    "# # for year in range(min(pd.to_datetime(df['receiptdate'], errors = 'coerce').dt.year), \n",
    "# #     datetime.strptime(snapshot_end, '%Y-%m-%d').year):\n",
    "# #     #datetime.strptime(\"2024-03-18\", '%Y-%m-%d').year):\n",
    "# #     plt.axvline(pd.to_datetime(df['receiptdate'], errors = 'coerce'), color = 'k', linestyle='--', alpha = 0.2)\n",
    "# #     #plt.axvline(pd.to_datetime(str(year) + '-01-01'), color = 'k', \n",
    "# #     #print(year)\n",
    "# plt.legend()    \n",
    "# #plt.savefig('UK_Actual_LPA_Data.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9843c8-2905-43ae-9974-1c184aeba587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the GROUP BY operation and calculate the count\n",
    "#Cases_by_year_age = lpa_df.groupby(\n",
    "#    ['receiptdate', 'uid', 'type', 'casesubtype', 'status', 'donor_postcode', 'donor_gender', 'age']) \\\n",
    "#    .agg({'No_of_Cases': 'count'}) \\ #['donor_postcode', 'donor_gender', 'age']\n",
    "#    .reset_index()\n",
    "\n",
    "#agg_funcs = dict(No_of_Cases = 'count')\n",
    "#Cases_by_year_age = lpa_df.set_index(['receiptdate', 'uid', 'type', 'casesubtype', 'status', 'donor_postcode', 'donor_gender', 'age']) \\\n",
    "#    .stack() \\\n",
    "#    .groupby(level=0) \\\n",
    "#    .agg(agg_funcs)\n",
    "\n",
    "\n",
    "#Cases_by_year_age\n",
    "#lpa_by_year_age = lpa_df[['receiptdate', 'uid', 'type', 'casesubtype', 'status', 'donor_postcode', 'donor_gender', 'age']] \\\n",
    "#                    .groupby(['donor_postcode', 'donor_gender', 'age'])  \\\n",
    "#                    .agg('count')#.sum()\n",
    "#lpa_by_year_age.to_csv(r'lpa_by_year_age.csv')\n",
    "\n",
    "\n",
    "\n",
    "#lpa_df.to_csv(r'lpa_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07154148-04e8-4096-918b-625a4fed04b8",
   "metadata": {},
   "source": [
    "# Missing age imutation\n",
    "\n",
    "There are two issues with the age:\n",
    "\n",
    "1. The donor_gender might be missing or entered incorrectly\n",
    "\n",
    "2. The derieved age might be higher than 126 years old\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae75203-0855-4e72-acb2-58504559db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc93e9-5ef4-465b-b364-daf4c3893f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed109d-7ce6-4e76-a6f2-0712c10f1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_data_sample_imputed = lpa_df\n",
    "\n",
    "# Filter rows with negative or greater than 126 age values\n",
    "criteria = lpa_data_sample_imputed[(lpa_data_sample_imputed['age'] < 0) | (lpa_data_sample_imputed['age'] > 126)]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(criteria)\n",
    "\n",
    "# Replace age values with NULL (NaN) in the filtered rows\n",
    "lpa_data_sample_imputed.loc[criteria.index, 'age'] = np.nan #None\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(lpa_data_sample_imputed)\n",
    "\n",
    "# Group by year and count age groups\n",
    "age_distribution = lpa_data_sample_imputed.groupby('year')['age'].value_counts()\n",
    "\n",
    "# Fill missing ages with the most common age for each year\n",
    "most_common_age = lpa_data_sample_imputed.groupby('year')['age'].apply(lambda x: x.mode().iloc[0])\n",
    "lpa_data_sample_imputed['age'] = lpa_data_sample_imputed.apply(lambda row: most_common_age[row['year']] if pd.isna(row['age']) else row['age'], axis=1)\n",
    "\n",
    "# Display the age distribution after filling missing ages\n",
    "print(\"\\nAge distribution by year (including filled missing ages):\")\n",
    "print(age_distribution)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(\"\\nFinal DataFrame:\")\n",
    "print(lpa_data_sample_imputed)\n",
    "\n",
    "# Save the dataframe with imputed ages\n",
    "lpa_data_sample_imputed.to_csv('lpa_data_sample_imputed.csv', index=False)\n",
    "\n",
    "# Print a success message\n",
    "print(\"The missing age data has been successfully imputed and saved to lpa_data_sample_imputed.csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedfc27-b664-4e22-b06a-ef0bf64c9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lpa_data_sample_imputed = lpa_df\n",
    "\n",
    "\n",
    "# # Identify the rows with missing age (represented as negative numbers)\n",
    "# ## 1. The donor_gender might be missing or entered incorrectly:  < 0\n",
    "# ## 2. The derieved age might be higher than 126 years old > 126\n",
    "# lpa_data_sample_imputed['missing_age'] = (lpa_data_sample_imputed['age'] < 0) | (lpa_data_sample_imputed['age'] > 126)\n",
    "\n",
    "# # Replace negative ages with NaN\n",
    "# lpa_data_sample_imputed.loc[missing_age, 'age'] = np.nan\n",
    "\n",
    "# # Calculate the age distribution for each year excluding missing ages\n",
    "# age_distribution = lpa_data_sample_imputed.loc[~missing_age].groupby('year')['age'].value_counts(normalize=True)\n",
    "\n",
    "# # Calculate the age distribution for each year\n",
    "# age_distribution_per_year = lpa_data_sample_imputed.groupby('year')['age'].value_counts(normalize=True)\n",
    "\n",
    "# # Apply the age distribution to the total number of donors in each year\n",
    "# for year in df['year'].unique():\n",
    "#     # Calculate the number of missing ages in the current year\n",
    "#     num_missing = missing_age & (df['year'] == year)\n",
    "    \n",
    "#     # If there are missing ages in the current year\n",
    "#     if num_missing.sum() > 0:\n",
    "#         # Generate ages according to the age distribution of the current year\n",
    "#         imputed_ages = np.random.choice(age_distribution[year].index, \n",
    "#                                         p=age_distribution[year].values, \n",
    "#                                         size=num_missing.sum())\n",
    "        \n",
    "#         # Assign the generated ages to the missing ages\n",
    "#         df.loc[num_missing, 'age'] = imputed_ages\n",
    "\n",
    "\n",
    "# # Apply the age distribution to the missing ages\n",
    "# for year in lpa_data_sample_imputed['year'].unique():\n",
    "#     missing_age_indices = lpa_data_sample_imputed[(lpa_data_sample_imputed['year'] == year) & (lpa_data_sample_imputed['age'].isna())].index\n",
    "#     if not missing_age_indices.empty:\n",
    "#         imputed_ages = np.random.choice(age_distribution_per_year[year].index, \n",
    "#                                         p=age_distribution_per_year[year].values, \n",
    "#                                         size=len(missing_age_indices))\n",
    "#         lpa_data_sample_imputed.loc[missing_age_indices, 'age'] = imputed_ages\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0916770-95b6-4bff-8b14-b1d103bc585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique identifier based on multiple columns:\n",
    "# lpa_unique_key = lpa_df\n",
    "\n",
    "\n",
    "# #df1.set_index(['donor_postcode', 'donor_gender', 'age']).index.factorize()[0]+1\n",
    "# lpa_unique_key.insert(loc = 0, column='ukey', value = lpa_unique_key.set_index(['donor_postcode', 'donor_gender', 'age']).index.factorize()[0]+1)\n",
    "# #lpa_unique_key\n",
    "\n",
    "# #(lpa_unique_key.fillna({'donor_postcode':'', 'donor_gender':'', 'age':''})\n",
    "# #   .groupby(['donor_postcode', 'donor_gender', 'age'],sort=False).ngroup()+1)\n",
    "\n",
    "# #lpa_unique_key.loc[lpa_unique_key['type']=='lpa','ukey'].agg(['nunique','count','size'])\n",
    "# #lpa_unique_key.query('type == \"lpa\"')['ukey'].agg(['nunique','count','size'])\n",
    "# #lpa_unique_key.query('casesubtype == \"hw\"')['ukey'].agg(['nunique','count','size'])\n",
    "# #lpa_unique_key.query('casesubtype == \"pfa\"')['ukey'].agg(['nunique','count','size'])\n",
    "# #lpa_unique_key.groupby(['ukey']).count()\n",
    "# #lpa_unique_key['count_ukey'] = lpa_unique_key['ukey'].value_counts()\n",
    "# #lpa_unique_key\n",
    "\n",
    "\n",
    "\n",
    "# lpa_unique_key['CountbyUkey'] = lpa_unique_key.groupby(['donor_postcode', 'donor_gender']).age.transform('count')\n",
    "# lpa_unique_key['CountbyAge'] = lpa_unique_key.groupby('year').age.transform('count').sum()\n",
    "\n",
    "# # Perform the GROUP BY operation and calculate the sum\n",
    "# lpa_age = lpa_unique_key.groupby(['donor_postcode', 'donor_gender', 'age']) \\\n",
    "#     .agg({'CountbyAge': 'sum'}) \\\n",
    "#     .reset_index()\n",
    "\n",
    "# print(lpa_age)\n",
    "# #lpa_unique_key['month'] = lpa_unique_key['ArrivalDate'].dt.month\n",
    "\n",
    "\n",
    "# # Cases_by_year_age\n",
    "\n",
    "# #lpa_by_year_age = lpa_unique_key[['receiptdate', 'uid', 'type', 'casesubtype', 'status', 'donor_postcode', 'donor_gender', 'age']] \\\n",
    "# #                    .groupby(['donor_postcode', 'donor_gender', 'age'])  \\\n",
    "# #                    .agg('count')#.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f2311-c45a-4016-ac0e-f2ca2a88c588",
   "metadata": {},
   "source": [
    "# Generate a Unique key by combining age, donor_gender, and donor_postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c4dde-0614-45ab-91a1-254117ca8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataFrame with the count of unique records for each combination of age and year. \n",
    "# Generate a unique key by combining age, donor_gender, and donor_postcode, \n",
    "# and then calculate the number of unique records by age and year.\n",
    "\n",
    "lpa_unique = lpa_data_sample_imputed\n",
    "\n",
    "# Remove spaces from the donor postcodes\n",
    "lpa_unique['donor_postcode'] = lpa_unique['donor_postcode'].str.strip()\n",
    "lpa_unique['donor_postcode'] = lpa_unique['donor_postcode'].str.replace(' ', '')\n",
    "\n",
    "# Generate a unique key by combining age, donor_gender, and donor_postcode\n",
    "lpa_unique['unique_key'] = lpa_unique['donor_dob'].astype(str) \\\n",
    "+ lpa_unique['donor_gender'] + lpa_unique['donor_postcode']\n",
    "\n",
    "# lpa_by_year_age = lpa_unique_key\n",
    "\n",
    "# lpa_by_year_age.to_csv(r'lpa_by_year_age.csv')\n",
    "\n",
    "# remove duplicate rows based on Id values(unique_key) and \n",
    "# keep only the row that don't have 0 value in all the fields.\n",
    "\n",
    "\n",
    "duplicateMask = lpa_unique.duplicated('unique_key', keep=False)\n",
    "\n",
    "lpa_unique = pd.concat([lpa_unique.loc[duplicateMask & lpa_unique[['age', 'donor_gender', 'donor_postcode']].ne(0).any(axis=1)], \\\n",
    "               lpa_unique[~duplicateMask]])\n",
    "\n",
    "#lpa_df['zero']=lpa_df.select_dtypes(['int','float']).eq(0).sum(axis=1)\n",
    "#df=df.sort_values(['zero','Id']).drop_duplicates(subset=['Id']).drop(columns='zero')df['zero']=df.select_dtypes(['int','float']).eq(0).sum(axis=1)\n",
    "#df=df.sort_values(['zero','Id']).drop_duplicates(subset=['Id']).drop(columns='zero')\n",
    "\n",
    "lpa_unique = lpa_unique.drop_duplicates(subset=\"unique_key\")\n",
    "lpa_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4fb88-82cb-4844-bcae-72657302a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Sort the rows of dataframe by  'unique_key'  \n",
    "# column inplace\n",
    "\n",
    "lpa_df_index = lpa_unique.sort_values(lpa_unique.columns[9])\n",
    "\n",
    "\n",
    "#lpa_df_index = lpa_unique.sort_values['unique_key']\n",
    "#lpa_df_index = lpa_unique.sort_values(by = 'unique_key', axis = 1, inplace = True, ascending = True)\n",
    "#lpa_df_index = lpa_unique.reindex(sorted(lpa_unique.columns), axis=1)\n",
    "\n",
    "## Set index\n",
    "#df['receiptdate'] = pd.to_datetime(df['receiptdate'])\n",
    "\n",
    "#df = df.set_index('receiptdate').asfreq('D')\n",
    "#lpa_df_index['unique_key'] = \n",
    "\n",
    "lpa_df_index.set_index('unique_key', inplace = True)\n",
    "\n",
    "#df.index = df.index.to_period('D')\n",
    "                            \n",
    "###print(df.head())\n",
    "###print(df.tail())\n",
    "\n",
    "#Missing_data = lpa_df_index[(lpa_data_sample_imputed['age'] < 0 | lpa_data_sample_imputed['age'] > 126)]\n",
    "#print(Missing_data)\n",
    "\n",
    "# Extract and save data into a csv file\n",
    "lpa_data = lpa_df_index\n",
    "lpa_data.to_csv(r'lpa_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ed0a3d-b058-41e4-8cbc-61cd51c67b72",
   "metadata": {},
   "source": [
    "# Missing Data Imputation:\n",
    "\n",
    "There are be some people in the LPA data with missing age (they are represented with negetive numbers in column age). \n",
    "So for missing data (age) imputation, his code is written to use age distribution of cases that they have age and\n",
    "apply this to the total number of doners in that year. \n",
    "Actually, we allocate proportionaly distributed age across each year of these missing ages. \n",
    "E.g., if we get 90% of age distribution for a particular year,\n",
    "we used this age distribution to be applied to the 100% of donors to get the total distribution. \n",
    "\n",
    "The code below: \n",
    "first, loads the data from the CSV file and replaces negative ages \n",
    "with NaN to represent missing data. \n",
    "\n",
    "It then calculates the age distribution for each year. \n",
    "\n",
    "For each year, it finds the indices of the missing ages and imputes \n",
    "them by randomly choosing from the age distribution of that year. \n",
    "\n",
    "The imputed ages are proportional to the age distribution \n",
    "of the donors that year. \n",
    "\n",
    "Finally, it saves the DataFrame with the imputed ages to a new CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0a4fd-f395-40b0-b785-c361f1b11029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate the number of unique records by age, year, gender, and postcode\n",
    "# #def calculate_unique_records_by_age_year_gender_postcode(records):\n",
    "# # Get the current year\n",
    "# #current_year = datetime.now().year  \n",
    "# #Create a dictionary to store counts for each age, year, gender, and postcode combination\n",
    "# age_year_gender_postcode_counts = {}\n",
    "\n",
    "# records = lpa_df\n",
    "    \n",
    "# # Iterate over each record\n",
    "# for record in records:         \n",
    "#     # Extract gender and postcode\n",
    "#     gender = record[\"donor_gender\"]\n",
    "#     postcode = record[\"donor_postcode\"]\n",
    "#     dob = record[\"donor_dob\"]\n",
    "    \n",
    "#     # Create a unique key combining age, gender, and postcode\n",
    "#     key = (dob, gender, postcode)\n",
    "        \n",
    "#     # Increment the count for the key\n",
    "#     age_year_gender_postcode_counts[key] = age_year_gender_postcode_counts.get(key, 0) + 1\n",
    "        \n",
    "# return age_year_gender_postcode_counts\n",
    "\n",
    "# # Call the function and print the results\n",
    "# unique_records_by_age_year_gender_postcode = calculate_unique_records_by_age_year_gender_postcode(records)\n",
    "\n",
    "# print(\"Number of unique records by age, year, gender, and postcode:\")\n",
    "\n",
    "# for key, count in unique_records_by_age_year_gender_postcode.items():\n",
    "#     dob, gender, postcode = key\n",
    "#     print(f\"Date of Birth (D.o.B): {dob}, Gender: {gender}, Postcode: {postcode}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12141e7-3cf6-4e44-9040-156be6692d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year of reciept from the receiptdate\n",
    "#receipt_year = int(record[\"receiptdate\"].split(\"-\")[0])\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the number of unique records by age and year\n",
    "count_unique_records = lpa_data.groupby(['year', 'donor_gender', 'age'])['uid'].nunique().reset_index(name='count')\n",
    "\n",
    "\n",
    "#unique_records = df.groupby('unique_key').agg('count').reset_index()  #.groupby(['year'])['unique_key'].nunique().reset_index(name='count')\n",
    "count_unique_records = count_unique_records.rename(columns={\"count\": \"Count_of_CASEID\"})\n",
    "\n",
    "# Display the result\n",
    "print(count_unique_records)\n",
    "\n",
    "# Save the result into a csv file\n",
    "count_unique_records.to_csv(r'count_unique_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536470b-17c0-4b89-b941-f75b0f54ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the receiptdate\n",
    "#receipt_year = birth_year        \n",
    "\n",
    "# Calculate the age of the person\n",
    "#age = receiptdate - birth_year\n",
    "#lpa_df['a'] = \n",
    "############(pd.to_datetime(lpa_df['receiptdate'], errors = 'coerce').dt.day - pd.to_datetime(lpa_df['donor_dob'], errors = 'coerce').dt.day) # / 365.25\n",
    "#lpa_df\n",
    "\n",
    "\n",
    "import xlsxwriter \n",
    "# Create an Excel writer\n",
    "writer = pd.ExcelWriter('LPA_Data_actuals_Years.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Iterate through unique years and save data to separate sheets\n",
    "for year in count_unique_records['year'].unique():\n",
    "    year_data = count_unique_records[count_unique_records['year'] == year]\n",
    "    year_data.to_excel(writer, sheet_name=str(year), index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()\n",
    "writer.close()  # Close the ExcelWriter\n",
    "\n",
    "\n",
    "# # Iterate through unique years and save data to separate sheets\n",
    "# for year in lpa_df['year'].unique():\n",
    "#     year_data = lpa_df[lpa_df['year'] == year]\n",
    "#     chunk_size = 100000  # Adjust as needed\n",
    "#     num_chunks = len(year_data) // chunk_size + 1\n",
    "#     for i in range(num_chunks):\n",
    "#         start_idx = i * chunk_size\n",
    "#         end_idx = (i + 1) * chunk_size\n",
    "#         chunk_data = lpa_df.iloc[start_idx:end_idx]\n",
    "#         chunk_data.to_excel(writer, sheet_name=f'Sheet{i}', index=False)\n",
    "\n",
    "# # Save the Excel file\n",
    "# writer.save()\n",
    "# writer.close()  # Close the ExcelWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce1de0-088c-4447-a432-f0dce3facfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will output the number of unique records for each age in each year for each donor gender in each donor postcode.\n",
    "# It calculates the age based on the current year and the birth year of each person in the records.\n",
    "# Then, it creates a unique key combining age, year, gender, and postcode, and increments the count for each key.\n",
    "# Finally, it prints the results showing the count of unique records for each combination.\n",
    "\n",
    "#from datetime import datetime\n",
    "\n",
    "# Sample data representing records with donor gender, donor postcode, and date of birth\n",
    "#records = [\n",
    "#    {\"donor_gender\": \"Male\", \"donor_postcode\": \"AB12 3CD\", \"date_of_birth\": \"1999-05-15\"},\n",
    "#    {\"donor_gender\": \"Female\", \"donor_postcode\": \"XY34 5YZ\", \"date_of_birth\": \"1994-08-20\"},\n",
    "#    {\"donor_gender\": \"Male\", \"donor_postcode\": \"CD56 7EF\", \"date_of_birth\": \"1996-02-10\"},\n",
    "#    {\"donor_gender\": \"Male\", \"donor_postcode\": \"FG78 9HI\", \"date_of_birth\": \"2000-11-30\"},\n",
    "#    {\"donor_gender\": \"Female\", \"donor_postcode\": \"JK90 1LM\", \"date_of_birth\": \"1987-03-25\"},\n",
    "#    {\"donor_gender\": \"Male\", \"donor_postcode\": \"OP23 4QR\", \"date_of_birth\": \"1993-09-05\"}\n",
    "#]\n",
    "\n",
    "# Function to calculate the number of unique records by age, year, gender, and postcode\n",
    "#def calculate_unique_records_by_age_year_gender_postcode(records):\n",
    "    # Get the current year\n",
    "#    current_year = datetime.now().year\n",
    "    \n",
    "    # Create a dictionary to store counts for each age, year, gender, and postcode combination\n",
    "#    age_year_gender_postcode_counts = {}\n",
    "    \n",
    "    # Iterate over each record\n",
    "#    for record in records:\n",
    "        # Extract the year of birth from the date_of_birth\n",
    "#        birth_year = int(record[\"date_of_birth\"].split(\"-\")[0])\n",
    "        \n",
    "        # Calculate the age of the person\n",
    "#        age = current_year - birth_year\n",
    "        \n",
    "        # Extract the year from the date_of_birth\n",
    "#        year = birth_year\n",
    "        \n",
    "        # Extract gender and postcode\n",
    "#        gender = record[\"donor_gender\"]\n",
    "#        postcode = record[\"donor_postcode\"]\n",
    "        \n",
    "        # Create a unique key combining age, year, gender, and postcode\n",
    "#        key = (age, year, gender, postcode)\n",
    "        \n",
    "        # Increment the count for the key\n",
    "#        age_year_gender_postcode_counts[key] = age_year_gender_postcode_counts.get(key, 0) + 1\n",
    "        \n",
    "#    return age_year_gender_postcode_counts\n",
    "\n",
    "# Call the function and print the results\n",
    "#unique_records_by_age_year_gender_postcode = calculate_unique_records_by_age_year_gender_postcode(records)\n",
    "#print(\"Number of unique records by age, year, gender, and postcode:\")\n",
    "#for key, count in unique_records_by_age_year_gender_postcode.items():\n",
    "#    age, year, gender, postcode = key\n",
    "#    print(f\"Age: {age}, Year: {year}, Gender: {gender}, Postcode: {postcode}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7b3db-0582-4c65-8ca5-f682932c572d",
   "metadata": {},
   "source": [
    "# Mortality Statistics\n",
    "## Source Data For Mortality Statistics and Modelled Age Specific Survival Rates (Model Input Set By Control Assumptions)\n",
    "\n",
    "# LPA Control Assumptions\n",
    "## Specific Key Assumptions that control expected demand , LPA market size and saturation.\n",
    "\n",
    "\n",
    "# Meta data and Variable selection and Data Cleaning for the Mortality statastics data based on population projections:\n",
    "\n",
    "## Goal: \n",
    "### What proportion of the UK population are likely to buy LPA and still alive?\n",
    "*How many people are still alive (Living Donors bought LPA)*\n",
    "*Based on ONS Data of Population of Engalnd and Wales, how many people are still alive and how many of them are dead?*\n",
    "*e.g., if there are 1000 people and 100 of them are still alive and bought LPA,\n",
    "so there are 900 of them still didn't buy LPA.\n",
    "\n",
    "\n",
    "\n",
    "**1. These rates are standardised to the 2013 European Standard Population, expressed per million population; \n",
    "they allow comparisons between populations with different age structures, including between males and females and over time. \n",
    "**2.  Deaths per 1,000 live births. \n",
    "**3.  Death figures are based on deaths registered rather than deaths occurring in a calendar year.\n",
    "\n",
    "### For information on registration delays for a range of causes, see: \n",
    "    https://webarchive.nationalarchives.gov.uk/ukgwa/20160106020016/http://www.ons.gov.uk/ons/guide-method/user-guidance/health-and-life-events/impact-of-registration-delays-on-mortality-statistics/index.html\n",
    "\n",
    "A limiting factor in modelling numbers of surving LPA holders aged 90+ has been the absence of single age specific mortality rates \n",
    "for this group. Estimates* suggested that previously applied mortality rates were too low increasing the apparent numbers of \n",
    "surviving LPA holder saged 90+ and therefore over-estimating the \"sauration of this market.\n",
    "\n",
    "For the 2018 LPA forecast , Age specific mortality rates for those aged 90+ have therefore been extrapolated based on \n",
    "a standard log power law that best fits existing mortality rates to age. \n",
    "\n",
    "*numbers of surviving LPA holders were estimated to exceed the total projected  population in each age group which was \n",
    "clearly not possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b287ad4-7294-4a75-a9e7-71d4f397b8da",
   "metadata": {},
   "source": [
    "# LPA SURVIVAL TABLES:\n",
    " LPA MODEL/LPA SURVIVAL TABLES\n",
    "percentage of people are died in one year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6b618-1161-4001-94c2-df536c5a7953",
   "metadata": {},
   "source": [
    "# if a 1000 40 years old male bought an LPA in 2008, what proportion of are still alove today?\n",
    "\n",
    "# The model taking each age categories (categorical variable) and assumed that they are \n",
    "# singe age-specifics in the age category 18 to 90 and provide figure what percentage of people for male died within one year?\n",
    "\n",
    "## e.g., in the 15-19 age category, 0.3 percent of males died within one year in the UK and 0.03 per 1000\n",
    "## e.g., in the 25-29 age category, 0.6 percent of males died within one year in the UK and 0.06 per 1000\n",
    "## e.g., in the 70-74 age category, 23.7 percent of males died within one year in the UK or 2.37 per 1000\n",
    "\n",
    "## if you started at age 18, 7 years and become 25 years old ahead, \n",
    "## as the ages goes up you will fall into a higher mortality category (from 0.3 to 0.6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7819c209-792e-47bb-ba4e-570d923b1c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
